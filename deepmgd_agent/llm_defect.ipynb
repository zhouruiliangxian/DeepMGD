{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "global input_path \n",
    "global output_path\n",
    "\n",
    "\n",
    "\n",
    "def send_image_to_server(image_path, output_path):\n",
    "    url = \"http://127.0.0.1:8000/process_image\"  # 服务地址\n",
    "    with open(image_path, \"rb\") as file:\n",
    "        files = {\"image\": file}\n",
    "        data = {\"out_file\": output_path}  # 发送字符串\n",
    "        response = requests.post(url, files=files, data=data)\n",
    "        if response.status_code == 200:\n",
    "            return f\"Server Response:{response.json()}\"\n",
    "        else:\n",
    "            return f\"Error:{response.json()}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\"messages\": [(\"human\", \"excute code print(\\'Hello, world! I love you\\')\")]}, stream_mode=\"values\"\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from autogen_core.base import CancellationToken\n",
    "from autogen_core.components.tools import PythonCodeExecutionTool\n",
    "from autogen_ext.code_executors import DockerCommandLineCodeExecutor\n",
    "\n",
    "# Create the tool.\n",
    "code_executor = DockerCommandLineCodeExecutor()\n",
    "await code_executor.start()\n",
    "code_execution_tool = PythonCodeExecutionTool(code_executor)\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "@tool\n",
    "async def code_executor(code: str):\n",
    "    \"\"\"excute code in the python environment, return result\"\"\"\n",
    "    result = await code_execution_tool.run_json({\"code\": code}, cancellation_token)\n",
    "\n",
    "    return code_execution_tool.return_value_as_string(result)\n",
    "\n",
    "@tool\n",
    "def detect_defects():\n",
    "    \"\"\"detect defects\"\"\"\n",
    "    text = \"The defect types are two: impurity and void.\"\n",
    "    # label = \"void :[ 298.8452,  525.0196,  580.6752,  998.5887]\"\n",
    "    format = \"The format of the JSON is: 'defect name : defect coordinate [x1, y1, x2, y2]'. These are the detected defects:\"\n",
    "    \n",
    "    res = send_image_to_server(input_path,output_path)\n",
    "    return text+format+res\n",
    "\n",
    "tools = [code_executor, detect_defects]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"GLM-4-plus\",\n",
    "    openai_api_key=\"your api key\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "model_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "\n",
    "\n",
    "def should_continue(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\"\"\"\n",
    "{\"messages\": [(\"human\", \"excute code print('Hello, world! I love you')\")]}, stream_mode=\"values\"\n",
    "\"\"\"\n",
    "# await app.ainvoke({\"messages\": [(\"human\", \"detect defects and then calculate the defects' area. once you use the code tool, your code you provide should print the code execution result.\")]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7880\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7880/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "\n",
    "# 主函数\n",
    "async def process_images_with_watermark(message, history):\n",
    "    # uploaded_images = message[\"files\"]\n",
    "    # processed_images = []\n",
    "    response=[]\n",
    "\n",
    "    if message.get(\"files\"):\n",
    "        for file in message[\"files\"]:\n",
    "            \n",
    "            global input_path\n",
    "            global output_path\n",
    "            input_dir = \"D:\\\\llm\\\\langchain\\\\缺陷检测\\\\input\"\n",
    "            output_dir = \"D:\\\\llm\\\\langchain\\\\缺陷检测\\\\output\"\n",
    "            os.makedirs(input_dir, exist_ok=True)  # 创建临时目录\n",
    "\n",
    "            input_path = os.path.join(input_dir, os.path.basename(file))\n",
    "            output_path = os.path.join(output_dir, os.path.basename(file))\n",
    "            \n",
    "\n",
    "            image = Image.open(file).convert(\"RGB\")\n",
    "            image.save(input_path)\n",
    "\n",
    "            input_message = HumanMessage(content=\"System: For math-related problems, please use the code tool. Ensure that the provided code prints the execution result. \\n \\n \"+message['text'])\n",
    "            res = await app.ainvoke({\"messages\": input_message },config)\n",
    "            # res = send_image_to_server(input_path,output_path)\n",
    "            \n",
    "            response.append(res[\"messages\"][-1].content)\n",
    "            # watermarked_image.save(output_path)\n",
    "            response.append(gr.Image(output_path))\n",
    "    else:\n",
    "\n",
    "        input_message = HumanMessage(content=\"System: For math-related problems, please use the code tool. Ensure that the provided code prints the execution result. \\n \\n \"+message['text'])\n",
    "        res = await app.ainvoke({\"messages\": input_message },config)\n",
    "        response.append(res[\"messages\"][-1].content)\n",
    "    return response\n",
    "    \n",
    "\n",
    "# 创建 Gradio 接口\n",
    "demo = gr.ChatInterface(\n",
    "    fn=process_images_with_watermark,\n",
    "    type=\"messages\",\n",
    "    examples=[\n",
    "        {\"text\": \"No files\", \"files\": []}\n",
    "    ],\n",
    "    multimodal=True,\n",
    "    textbox=gr.MultimodalTextbox(file_count=\"multiple\", file_types=[\"image\"], sources=[\"upload\"])\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
